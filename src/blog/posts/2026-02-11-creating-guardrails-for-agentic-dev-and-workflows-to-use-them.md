---
date: 2026-02-11
authors:
  - bernardo
categories:
  - General
draft: true
---
# What I see today
I see myself in a few scenarios when interacting with llms for programming and I want to reason how to improve them;
- having a fragile project and wnating to make it robust
  - the intuition is static tools and testing can easily spot this. So adding a loop of agentic generation and extensive tooling run and report and them -> report to agenic generation is key.
- I have this "pipeline" i.e. a sequence of python scripts clis , run them for this config.yaml use case. 

- this pattern already works, replicate it for a.another use case. 
 - 
# The ideal
I imagine two scenarios 

